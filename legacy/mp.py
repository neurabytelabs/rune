#!/usr/bin/env python3
"""
MP â€” Master Prompt Enhancer & Runner
KullanÄ±m:
  python3 mp.py "Bana bir blog yazÄ±sÄ± yaz"              # Enhance + Run
  python3 mp.py --raw "Bana bir blog yazÄ±sÄ± yaz"         # Sadece enhanced prompt gÃ¶ster
  python3 mp.py --compare "Bana bir blog yazÄ±sÄ± yaz"     # Raw vs Enhanced karÅŸÄ±laÅŸtÄ±rma
  python3 mp.py --model gemini-3-flash "prompt"           # FarklÄ± model
"""

import sys
import os
import json
import datetime

# Antigravity tools path
sys.path.insert(0, os.path.expanduser("~/.openclaw/workspace"))
from tools.antigravity import gemini

META_PROMPT = """Sen "Prompt Architect v4.4"sÃ¼n. GÃ¶revin: kullanÄ±cÄ±nÄ±n basit isteÄŸini alÄ±p
Master Prompt Template v4.4'Ã¼n 8 katmanlÄ± Polyglot yapÄ±sÄ±na uygun prompt Ã¼retmek.

KURALLAR:
1. v4.4 XML yapÄ±sÄ±nÄ± koru (L0-L7: System Core, Context Identity, Intent Scope, Governance, Cognitive Engine, Capabilities Domain, QA, Output Meta).
2. {{variable}} alanlarÄ±nÄ± gÃ¶reve gÃ¶re doldur.
3. Domain Preset seÃ§: CODING / WRITING / ANALYSIS.
4. Complexity L1-L5 belirle. L1-L2'de gereksiz katmanlarÄ± atla.
5. Observability iÃ§in aktif katmanlarÄ± belirt.
6. KullanÄ±cÄ± TÃ¼rkÃ§e yazdÄ±ysa TÃ¼rkÃ§e, Ä°ngilizce yazdÄ±ysa Ä°ngilizce Ã¼ret.
SADECE PROMPT'U VER."""

OUTPUT_DIR = os.path.expanduser("~/Developer/mrsarac/master-prompts/outputs")


def ensure_output_dir():
    today = datetime.date.today().isoformat()
    path = os.path.join(OUTPUT_DIR, today)
    os.makedirs(path, exist_ok=True)
    return path


def log_result(output_dir, user_prompt, enhanced_prompt, raw_output=None, enhanced_output=None, model="gemini-3-pro"):
    timestamp = datetime.datetime.now().strftime("%H%M%S")
    slug = user_prompt[:40].replace(" ", "_").replace("/", "-")
    filename = f"{timestamp}_{slug}.json"
    filepath = os.path.join(output_dir, filename)

    data = {
        "timestamp": datetime.datetime.now().isoformat(),
        "model": model,
        "user_prompt": user_prompt,
        "enhanced_prompt": enhanced_prompt,
        "raw_output": raw_output,
        "enhanced_output": enhanced_output,
    }

    with open(filepath, "w", encoding="utf-8") as f:
        json.dump(data, f, ensure_ascii=False, indent=2)

    return filepath


def enhance_prompt(user_prompt, model="gemini-3-pro"):
    """Meta-Prompt ile kullanÄ±cÄ± promptunu iyileÅŸtir."""
    full_prompt = f"{META_PROMPT}\n\nKULLANICI Ä°STEÄÄ°:\n{user_prompt}"
    return gemini(full_prompt, model=model)


def run_prompt(prompt, model="gemini-3-pro"):
    """Promptu modele gÃ¶nder ve Ã§Ä±ktÄ±yÄ± al."""
    return gemini(prompt, model=model)


def main():
    args = sys.argv[1:]

    if not args or args[0] in ("-h", "--help"):
        print(__doc__)
        return

    mode = "run"  # default: enhance + run
    model = "gemini-3-pro"
    prompt_parts = []

    i = 0
    while i < len(args):
        if args[i] == "--raw":
            mode = "raw"
        elif args[i] == "--compare":
            mode = "compare"
        elif args[i] == "--model" and i + 1 < len(args):
            model = args[i + 1]
            i += 1
        else:
            prompt_parts.append(args[i])
        i += 1

    user_prompt = " ".join(prompt_parts)
    if not user_prompt:
        print("Hata: Prompt vermedin.")
        return

    output_dir = ensure_output_dir()

    print(f"ğŸ§ª MP v4.1 | Model: {model} | Mod: {mode}")
    print(f"ğŸ“ Prompt: {user_prompt}\n")

    # Step 1: Enhance
    print("âš¡ Prompt iyileÅŸtiriliyor...")
    enhanced = enhance_prompt(user_prompt, model=model)
    print(f"\n{'='*60}")
    print("ğŸ“‹ ENHANCED PROMPT:")
    print(f"{'='*60}")
    print(enhanced)

    if mode == "raw":
        log_result(output_dir, user_prompt, enhanced, model=model)
        print(f"\nâœ… Log kaydedildi: {output_dir}")
        return

    # Step 2: Run enhanced prompt
    print(f"\n{'='*60}")
    print("ğŸš€ Enhanced prompt Ã§alÄ±ÅŸtÄ±rÄ±lÄ±yor...")
    print(f"{'='*60}")
    enhanced_output = run_prompt(enhanced, model=model)
    print(enhanced_output)

    if mode == "compare":
        # Step 3: Also run raw prompt
        print(f"\n{'='*60}")
        print("ğŸ“Š Ham prompt Ã§alÄ±ÅŸtÄ±rÄ±lÄ±yor (karÅŸÄ±laÅŸtÄ±rma)...")
        print(f"{'='*60}")
        raw_output = run_prompt(user_prompt, model=model)
        print(raw_output)

        print(f"\n{'='*60}")
        print("ğŸ“ˆ KARÅILAÅTIRMA:")
        print(f"  Raw Ã§Ä±ktÄ± uzunluÄŸu:      {len(raw_output)} karakter")
        print(f"  Enhanced Ã§Ä±ktÄ± uzunluÄŸu:  {len(enhanced_output)} karakter")
        print(f"{'='*60}")

        log_result(output_dir, user_prompt, enhanced, raw_output, enhanced_output, model=model)
    else:
        log_result(output_dir, user_prompt, enhanced, enhanced_output=enhanced_output, model=model)

    print(f"\nâœ… Log kaydedildi: {output_dir}")


if __name__ == "__main__":
    main()
